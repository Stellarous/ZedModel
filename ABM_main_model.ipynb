{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e998307c-40d6-4245-9d12-00a065b2696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa\n",
    "import mesa.space as space\n",
    "import mesa.time as time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ad30b1-839e-4c23-be38-69d26b57f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gambit not available. Install for advanced game theory analysis.\n"
     ]
    }
   ],
   "source": [
    "# For Gambit game theory analysis (you'll need to install gambit-python)\n",
    "try:\n",
    "    import gambit\n",
    "    GAMBIT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GAMBIT_AVAILABLE = False\n",
    "    print(\"Gambit not available. Install for advanced game theory analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37645d9-f439-481a-9e97-adfa039eeaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualProcessAgent(mesa.Agent):\n",
    "    \"\"\"\n",
    "    An agent with dual-process decision-making capabilities.\n",
    "    \n",
    "    This agent models the dual-process theory of cognition:\n",
    "    - System 1: Fast, intuitive, emotional thinking (veil of ignorance)\n",
    "    - System 2: Slow, deliberative, analytical thinking\n",
    "    \n",
    "    Under the veil of ignorance, agents don't know their future position\n",
    "    in society and make decisions from an impartial standpoint.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unique_id, model, system1_bias=0.7, \n",
    "                 fairness_preference=0.5, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initialize a dual-process agent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        unique_id : int\n",
    "            Unique identifier for the agent\n",
    "        model : mesa.Model\n",
    "            The model instance the agent belongs to\n",
    "        system1_bias : float (0-1)\n",
    "            Probability of using System 1 thinking vs System 2\n",
    "        fairness_preference : float (0-1)\n",
    "            Strength of fairness preference (1 = max fairness)\n",
    "        learning_rate : float (0-1)\n",
    "            How quickly the agent updates its strategies\n",
    "        \"\"\"\n",
    "        super().__init__(unique_id, model)\n",
    "        self.system1_bias = system1_bias\n",
    "        self.fairness_preference = fairness_preference\n",
    "        self.learning_rate = learning_rate\n",
    "        self.payoff_history = []\n",
    "        self.cooperation_history = []\n",
    "        self.system_used = []  # Track which system was used\n",
    "        \n",
    "        # System 2 deliberation parameters\n",
    "        self.deliberation_level = 0.0\n",
    "        self.analytical_capacity = random.uniform(0.5, 1.0)\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"Advance the agent by one step in the simulation.\"\"\"\n",
    "        # Update deliberation level based on context\n",
    "        self.update_deliberation()\n",
    "        \n",
    "        # Make decisions based on current game\n",
    "        if self.model.game_type == \"prisoners_dilemma\":\n",
    "            self.play_prisoners_dilemma()\n",
    "        elif self.model.game_type == \"resource_allocation\":\n",
    "            self.play_resource_allocation()\n",
    "    \n",
    "    def update_deliberation(self):\n",
    "        \"\"\"Update the agent's level of deliberative thinking.\"\"\"\n",
    "        # Stress or time pressure reduces deliberation\n",
    "        stress_factor = 1.0 - (self.model.schedule.steps / self.model.max_steps)\n",
    "        self.deliberation_level = (1 - self.system1_bias) * self.analytical_capacity * stress_factor\n",
    "    \n",
    "    def make_decision_under_veil(self, context):\n",
    "        \"\"\"\n",
    "        Make a decision under the veil of ignorance.\n",
    "        \n",
    "        The veil of ignorance forces agents to consider decisions\n",
    "        without knowing their own position, promoting impartiality.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        context : dict\n",
    "            Contextual information about the decision\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        decision : object\n",
    "            The agent's decision\n",
    "        \"\"\"\n",
    "        if random.random() < self.deliberation_level:\n",
    "            # Use System 2: Deliberative thinking\n",
    "            decision = self.system2_deliberative_decision(context)\n",
    "            self.system_used.append(2)\n",
    "        else:\n",
    "            # Use System 1: Intuitive thinking with veil of ignorance\n",
    "            decision = self.system1_veil_decision(context)\n",
    "            self.system_used.append(1)\n",
    "        \n",
    "        return decision\n",
    "    \n",
    "    def system1_veil_decision(self, context):\n",
    "        \"\"\"\n",
    "        System 1 decision-making under veil of ignorance.\n",
    "        \n",
    "        Fast, intuitive thinking that considers fairness from an\n",
    "        impartial perspective.\n",
    "        \"\"\"\n",
    "        # Under veil of ignorance, consider all possible positions\n",
    "        if context.get('game_type') == 'prisoners_dilemma':\n",
    "            # More likely to cooperate under veil of ignorance\n",
    "            cooperation_prob = 0.3 + (0.7 * self.fairness_preference)\n",
    "            return random.random() < cooperation_prob\n",
    "        \n",
    "        elif context.get('game_type') == 'resource_allocation':\n",
    "            # Fair distribution under veil\n",
    "            fair_share = context.get('total_resources', 100) / context.get('num_agents', 10)\n",
    "            base_demand = fair_share * (0.8 + 0.4 * self.fairness_preference)\n",
    "            # Add some noise\n",
    "            return max(0, base_demand * random.uniform(0.8, 1.2))\n",
    "    \n",
    "    def system2_deliberative_decision(self, context):\n",
    "        \"\"\"\n",
    "        System 2 deliberative decision-making.\n",
    "        \n",
    "        Slow, analytical thinking that calculates expected payoffs\n",
    "        and strategic considerations.\n",
    "        \"\"\"\n",
    "        if context.get('game_type') == 'prisoners_dilemma':\n",
    "            # Calculate expected payoff of cooperation vs defection\n",
    "            coop_payoff = self.calculate_expected_payoff(cooperate=True, context=context)\n",
    "            defect_payoff = self.calculate_expected_payoff(cooperate=False, context=context)\n",
    "            \n",
    "            # Include fairness consideration\n",
    "            fairness_bonus = 0.5 * self.fairness_preference\n",
    "            return (coop_payoff + fairness_bonus) > defect_payoff\n",
    "        \n",
    "        elif context.get('game_type') == 'resource_allocation':\n",
    "            # Strategic resource demand calculation\n",
    "            total_resources = context.get('total_resources', 100)\n",
    "            num_agents = context.get('num_agents', 10)\n",
    "            others_demand = context.get('others_demand_estimate', total_resources/num_agents)\n",
    "            \n",
    "            # Calculate optimal demand considering others' behavior\n",
    "            optimal = min(total_resources - (num_agents - 1) * others_demand, \n",
    "                         total_resources * 0.3)  # Don't be too greedy\n",
    "            \n",
    "            # Adjust for fairness\n",
    "            fair_adjustment = self.fairness_preference * (total_resources/num_agents - optimal)\n",
    "            return max(0, optimal + fair_adjustment * 0.5)\n",
    "    \n",
    "    def calculate_expected_payoff(self, cooperate, context):\n",
    "        \"\"\"\n",
    "        Calculate expected payoff for a decision.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        cooperate : bool\n",
    "            Whether the agent cooperates\n",
    "        context : dict\n",
    "            Decision context\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        expected_payoff : float\n",
    "            Expected payoff value\n",
    "        \"\"\"\n",
    "        if context.get('game_type') == 'prisoners_dilemma':\n",
    "            # Prisoner's dilemma payoff calculation\n",
    "            if cooperate:\n",
    "                # If both cooperate: R, if opponent defects: S\n",
    "                prob_coop = context.get('expected_cooperation_rate', 0.5)\n",
    "                return prob_coop * 3 + (1 - prob_coop) * 0\n",
    "            else:\n",
    "                # If opponent cooperates: T, if opponent defects: P\n",
    "                prob_coop = context.get('expected_cooperation_rate', 0.5)\n",
    "                return prob_coop * 5 + (1 - prob_coop) * 1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def play_prisoners_dilemma(self):\n",
    "        \"\"\"Play a prisoner's dilemma game with another agent.\"\"\"\n",
    "        partner = random.choice([a for a in self.model.schedule.agents if a != self])\n",
    "        \n",
    "        context = {\n",
    "            'game_type': 'prisoners_dilemma',\n",
    "            'partner_id': partner.unique_id,\n",
    "            'expected_cooperation_rate': self.model.get_cooperation_rate()\n",
    "        }\n",
    "        \n",
    "        # Make decision under veil of ignorance\n",
    "        my_decision = self.make_decision_under_veil(context)\n",
    "        partner_decision = partner.make_decision_under_veil(context)\n",
    "        \n",
    "        # Calculate payoffs\n",
    "        payoff = self.calculate_pd_payoff(my_decision, partner_decision)\n",
    "        self.payoff_history.append(payoff)\n",
    "        self.cooperation_history.append(1 if my_decision else 0)\n",
    "        \n",
    "        # Update model metrics\n",
    "        self.model.cooperation_count += 1 if my_decision else 0\n",
    "        self.model.defection_count += 0 if my_decision else 1\n",
    "    \n",
    "    def play_resource_allocation(self):\n",
    "        \"\"\"Play a resource allocation game.\"\"\"\n",
    "        context = {\n",
    "            'game_type': 'resource_allocation',\n",
    "            'total_resources': self.model.total_resources,\n",
    "            'num_agents': self.model.num_agents,\n",
    "            'others_demand_estimate': self.model.get_average_demand()\n",
    "        }\n",
    "        \n",
    "        # Make decision under veil of ignorance\n",
    "        demand = self.make_decision_under_veil(context)\n",
    "        \n",
    "        # Store demand for model-level calculation\n",
    "        self.current_demand = demand\n",
    "        self.model.current_demands.append(demand)\n",
    "    \n",
    "    def calculate_pd_payoff(self, my_choice, partner_choice):\n",
    "        \"\"\"\n",
    "        Calculate prisoner's dilemma payoff.\n",
    "        \n",
    "        Standard PD payoffs:\n",
    "        - Both cooperate: 3,3\n",
    "        - Both defect: 1,1  \n",
    "        - I defect, partner cooperates: 5,0\n",
    "        - I cooperate, partner defects: 0,5\n",
    "        \"\"\"\n",
    "        if my_choice and partner_choice:  # Both cooperate\n",
    "            return 3\n",
    "        elif not my_choice and not partner_choice:  # Both defect\n",
    "            return 1\n",
    "        elif not my_choice and partner_choice:  # I defect, partner cooperates\n",
    "            return 5\n",
    "        else:  # I cooperate, partner defects\n",
    "            return 0\n",
    "\n",
    "\n",
    "class DualProcessModel(mesa.Model):\n",
    "    \"\"\"\n",
    "    Model for simulating dual-process decision-making under veil of ignorance.\n",
    "    \n",
    "    This model explores how different cognitive processes affect\n",
    "    fairness, cooperation, and welfare in society.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_agents=50, width=20, height=20, \n",
    "                 game_type=\"prisoners_dilemma\", max_steps=1000,\n",
    "                 system1_distribution=\"uniform\"):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_agents : int\n",
    "            Number of agents in the model\n",
    "        width, height : int\n",
    "            Dimensions of the space (not used in all games)\n",
    "        game_type : str\n",
    "            Type of game being played (\"prisoners_dilemma\" or \"resource_allocation\")\n",
    "        max_steps : int\n",
    "            Maximum number of steps to run\n",
    "        system1_distribution : str\n",
    "            How System 1 bias is distributed (\"uniform\", \"skewed\", \"bimodal\")\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_agents = num_agents\n",
    "        self.grid = space.MultiGrid(width, height, True)\n",
    "        self.schedule = time.RandomActivation(self)\n",
    "        self.game_type = game_type\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Game-specific parameters\n",
    "        if game_type == \"resource_allocation\":\n",
    "            self.total_resources = 1000\n",
    "            self.current_demands = []\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.cooperation_count = 0\n",
    "        self.defection_count = 0\n",
    "        self.total_payoffs = 0\n",
    "        self.fairness_scores = []\n",
    "        self.welfare_scores = []\n",
    "        self.equality_scores = []\n",
    "        \n",
    "        # Create agents with specified distribution of System 1 bias\n",
    "        self.create_agents(system1_distribution)\n",
    "        \n",
    "        # Data collection\n",
    "        self.datacollector = mesa.DataCollector(\n",
    "            model_reporters={\n",
    "                \"Cooperation_Rate\": \"cooperation_rate\",\n",
    "                \"Average_Payoff\": \"average_payoff\", \n",
    "                \"Gini_Coefficient\": \"gini_coefficient\",\n",
    "                \"Total_Welfare\": \"total_welfare\",\n",
    "                \"Fairness_Score\": \"fairness_score\",\n",
    "                \"System1_Usage_Rate\": \"system1_usage_rate\"\n",
    "            },\n",
    "            agent_reporters={\n",
    "                \"Payoff\": \"payoff_history\",\n",
    "                \"Cooperation\": \"cooperation_history\",\n",
    "                \"System_Used\": \"system_used\",\n",
    "                \"Fairness_Preference\": \"fairness_preference\",\n",
    "                \"System1_Bias\": \"system1_bias\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def create_agents(self, distribution):\n",
    "        \"\"\"Create agents with specified distribution of cognitive traits.\"\"\"\n",
    "        for i in range(self.num_agents):\n",
    "            # Determine System 1 bias based on distribution\n",
    "            if distribution == \"uniform\":\n",
    "                system1_bias = random.uniform(0.1, 0.9)\n",
    "            elif distribution == \"skewed\":\n",
    "                # Most agents have high System 1 bias\n",
    "                system1_bias = min(0.9, max(0.1, random.betavariate(2, 5)))\n",
    "            elif distribution == \"bimodal\":\n",
    "                # Polarized population\n",
    "                system1_bias = random.uniform(0.1, 0.4) if random.random() < 0.5 else random.uniform(0.6, 0.9)\n",
    "            else:\n",
    "                system1_bias = random.uniform(0.1, 0.9)\n",
    "            \n",
    "            # Create agent\n",
    "            agent = DualProcessAgent(\n",
    "                unique_id=i,\n",
    "                model=self,\n",
    "                system1_bias=system1_bias,\n",
    "                fairness_preference=random.uniform(0.2, 0.8),\n",
    "                learning_rate=random.uniform(0.05, 0.2)\n",
    "            )\n",
    "            \n",
    "            self.schedule.add(agent)\n",
    "            \n",
    "            # Place agent on grid\n",
    "            x = random.randrange(self.grid.width)\n",
    "            y = random.randrange(self.grid.height)\n",
    "            self.grid.place_agent(agent, (x, y))\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Advance the model by one step.\"\"\"\n",
    "        # Reset game-specific trackers\n",
    "        if self.game_type == \"resource_allocation\":\n",
    "            self.current_demands = []\n",
    "        \n",
    "        # Advance all agents\n",
    "        self.schedule.step()\n",
    "        \n",
    "        # Calculate resource allocation if applicable\n",
    "        if self.game_type == \"resource_allocation\":\n",
    "            self.calculate_resource_allocation()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        self.calculate_metrics()\n",
    "        \n",
    "        # Collect data\n",
    "        self.datacollector.collect(self)\n",
    "        \n",
    "        self.current_step += 1\n",
    "    \n",
    "    def calculate_resource_allocation(self):\n",
    "        \"\"\"Calculate resource allocation based on demands.\"\"\"\n",
    "        total_demand = sum(self.current_demands)\n",
    "        \n",
    "        if total_demand <= self.total_resources:\n",
    "            # All demands can be satisfied\n",
    "            for i, agent in enumerate(self.schedule.agents):\n",
    "                payoff = min(agent.current_demand, self.total_resources * (agent.current_demand / total_demand))\n",
    "                agent.payoff_history.append(payoff)\n",
    "                self.total_payoffs += payoff\n",
    "        else:\n",
    "            # Demands exceed resources - proportional reduction\n",
    "            for i, agent in enumerate(self.schedule.agents):\n",
    "                payoff = self.total_resources * (agent.current_demand / total_demand)\n",
    "                agent.payoff_history.append(payoff)\n",
    "                self.total_payoffs += payoff\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        \"\"\"Calculate various social metrics.\"\"\"\n",
    "        # Cooperation rate (for PD)\n",
    "        if self.game_type == \"prisoners_dilemma\":\n",
    "            total_interactions = self.cooperation_count + self.defection_count\n",
    "            self.cooperation_rate = self.cooperation_count / total_interactions if total_interactions > 0 else 0\n",
    "        else:\n",
    "            self.cooperation_rate = 0\n",
    "        \n",
    "        # Average payoff\n",
    "        all_payoffs = []\n",
    "        for agent in self.schedule.agents:\n",
    "            if agent.payoff_history:\n",
    "                all_payoffs.append(agent.payoff_history[-1])\n",
    "        \n",
    "        self.average_payoff = np.mean(all_payoffs) if all_payoffs else 0\n",
    "        \n",
    "        # Gini coefficient (inequality measure)\n",
    "        self.gini_coefficient = self.calculate_gini(all_payoffs) if all_payoffs else 0\n",
    "        \n",
    "        # Total welfare\n",
    "        self.total_welfare = sum(all_payoffs) if all_payoffs else 0\n",
    "        \n",
    "        # Fairness score (based on Rawls' difference principle)\n",
    "        self.fairness_score = min(all_payoffs) / max(all_payoffs) if all_payoffs and max(all_payoffs) > 0 else 0\n",
    "        \n",
    "        # System 1 usage rate\n",
    "        system_uses = []\n",
    "        for agent in self.schedule.agents:\n",
    "            if agent.system_used:\n",
    "                system_uses.append(agent.system_used[-1])\n",
    "        self.system1_usage_rate = sum(1 for x in system_uses if x == 1) / len(system_uses) if system_uses else 0\n",
    "    \n",
    "    def calculate_gini(self, values):\n",
    "        \"\"\"Calculate Gini coefficient for inequality measurement.\"\"\"\n",
    "        if len(values) == 0:\n",
    "            return 0\n",
    "        \n",
    "        values = sorted(values)\n",
    "        n = len(values)\n",
    "        index = np.arange(1, n + 1)\n",
    "        return (np.sum((2 * index - n - 1) * values)) / (n * np.sum(values))\n",
    "    \n",
    "    def get_cooperation_rate(self):\n",
    "        \"\"\"Get current cooperation rate in the population.\"\"\"\n",
    "        return self.cooperation_rate if hasattr(self, 'cooperation_rate') else 0.5\n",
    "    \n",
    "    def get_average_demand(self):\n",
    "        \"\"\"Get average resource demand.\"\"\"\n",
    "        if hasattr(self, 'current_demands') and self.current_demands:\n",
    "            return np.mean(self.current_demands)\n",
    "        return self.total_resources / self.num_agents\n",
    "    \n",
    "    def run_model(self, n_steps=None):\n",
    "        \"\"\"Run the model for a specified number of steps.\"\"\"\n",
    "        if n_steps is None:\n",
    "            n_steps = self.max_steps\n",
    "        \n",
    "        for _ in range(n_steps):\n",
    "            self.step()\n",
    "\n",
    "\n",
    "class GameTheoryAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzer for game-theoretic properties using Gambit.\n",
    "    \n",
    "    This class provides tools to analyze the emergent game-theoretic\n",
    "    properties of the agent-based model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the game theory analyzer.\"\"\"\n",
    "        if not GAMBIT_AVAILABLE:\n",
    "            print(\"Warning: Gambit not available. Game theory analysis limited.\")\n",
    "    \n",
    "    def analyze_nash_equilibrium(self, payoffs):\n",
    "        \"\"\"\n",
    "        Analyze Nash equilibria of the emergent game.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        payoffs : array-like\n",
    "            Payoff matrix from the simulation\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        equilibria : list\n",
    "            List of Nash equilibria\n",
    "        \"\"\"\n",
    "        if not GAMBIT_AVAILABLE:\n",
    "            return [\"Gambit required for Nash equilibrium analysis\"]\n",
    "        \n",
    "        try:\n",
    "            # Create a strategic game\n",
    "            game = gambit.Game.new_table([2, 2])  # 2x2 game for demonstration\n",
    "            \n",
    "            # Set payoffs (example for prisoner's dilemma)\n",
    "            game[0, 0][0] = 3  # Both cooperate\n",
    "            game[0, 0][1] = 3\n",
    "            game[0, 1][0] = 0  # I cooperate, opponent defects  \n",
    "            game[0, 1][1] = 5\n",
    "            game[1, 0][0] = 5  # I defect, opponent cooperates\n",
    "            game[1, 0][1] = 0\n",
    "            game[1, 1][0] = 1  # Both defect\n",
    "            game[1, 1][1] = 1\n",
    "            \n",
    "            # Solve for Nash equilibria\n",
    "            solver = gambit.nash.ExternalEnumMixedSolver()\n",
    "            equilibria = solver.solve(game)\n",
    "            \n",
    "            return equilibria\n",
    "            \n",
    "        except Exception as e:\n",
    "            return [f\"Analysis failed: {str(e)}\"]\n",
    "    \n",
    "    def calculate_social_welfare(self, payoffs):\n",
    "        \"\"\"\n",
    "        Calculate social welfare metrics.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        payoffs : list\n",
    "            List of agent payoffs\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        metrics : dict\n",
    "            Dictionary of welfare metrics\n",
    "        \"\"\"\n",
    "        if not payoffs:\n",
    "            return {}\n",
    "        \n",
    "        payoffs = np.array(payoffs)\n",
    "        \n",
    "        metrics = {\n",
    "            'utilitarian': np.sum(payoffs),  # Sum of utilities\n",
    "            'rawlsian': np.min(payoffs),     # Welfare of worst-off\n",
    "            'nash': np.prod(payoffs),        # Nash social welfare\n",
    "            'egalitarian': np.std(payoffs)   # Equality measure (inverse)\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def run_experiment():\n",
    "    \"\"\"Run a complete experiment with different parameter settings.\"\"\"\n",
    "    print(\"Running Dual-Process Decision Making Experiment\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test different scenarios\n",
    "    scenarios = [\n",
    "        (\"High System 1 Bias\", \"skewed\", \"prisoners_dilemma\"),\n",
    "        (\"Balanced Cognition\", \"uniform\", \"prisoners_dilemma\"), \n",
    "        (\"Resource Allocation\", \"uniform\", \"resource_allocation\"),\n",
    "        (\"Polarized Cognition\", \"bimodal\", \"prisoners_dilemma\")\n",
    "    ]\n",
    "    \n",
    "    for scenario_name, system1_dist, game_type in scenarios:\n",
    "        print(f\"\\nRunning scenario: {scenario_name}\")\n",
    "        \n",
    "        # Initialize and run model\n",
    "        model = DualProcessModel(\n",
    "            num_agents=50,\n",
    "            game_type=game_type,\n",
    "            system1_distribution=system1_dist,\n",
    "            max_steps=500\n",
    "        )\n",
    "        model.run_model()\n",
    "        \n",
    "        # Collect results\n",
    "        model_data = model.datacollector.get_model_vars_dataframe()\n",
    "        agent_data = model.datacollector.get_agent_vars_dataframe()\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        final_cooperation = model_data['Cooperation_Rate'].iloc[-1] if game_type == \"prisoners_dilemma\" else 0\n",
    "        final_welfare = model_data['Total_Welfare'].iloc[-1]\n",
    "        final_equality = 1 - model_data['Gini_Coefficient'].iloc[-1]  # Convert to equality measure\n",
    "        final_fairness = model_data['Fairness_Score'].iloc[-1]\n",
    "        \n",
    "        scenario_result = {\n",
    "            'scenario': scenario_name,\n",
    "            'system1_distribution': system1_dist,\n",
    "            'game_type': game_type,\n",
    "            'cooperation_rate': final_cooperation,\n",
    "            'total_welfare': final_welfare,\n",
    "            'equality': final_equality,\n",
    "            'fairness': final_fairness,\n",
    "            'system1_usage': model_data['System1_Usage_Rate'].iloc[-1]\n",
    "        }\n",
    "        \n",
    "        results.append(scenario_result)\n",
    "        \n",
    "        print(f\"  Cooperation: {final_cooperation:.3f}\")\n",
    "        print(f\"  Welfare: {final_welfare:.2f}\")\n",
    "        print(f\"  Equality: {final_equality:.3f}\")\n",
    "        print(f\"  Fairness: {final_fairness:.3f}\")\n",
    "        print(f\"  System 1 Usage: {scenario_result['system1_usage']:.3f}\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Experiment Complete\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return results_df, model_data, agent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4cc0e3-f3a2-47dc-bd3d-b69952e0eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Dual-Process Decision Making Experiment\n",
      "==================================================\n",
      "\n",
      "Running scenario: High System 1 Bias\n",
      "  Cooperation: 0.472\n",
      "  Welfare: 133.00\n",
      "  Equality: 0.612\n",
      "  Fairness: 0.000\n",
      "  System 1 Usage: 1.000\n",
      "\n",
      "Running scenario: Balanced Cognition\n",
      "  Cooperation: 0.531\n",
      "  Welfare: 142.00\n",
      "  Equality: 0.654\n",
      "  Fairness: 0.000\n",
      "  System 1 Usage: 1.000\n",
      "\n",
      "Running scenario: Resource Allocation\n",
      "  Cooperation: 0.000\n",
      "  Welfare: 1000.00\n",
      "  Equality: 0.916\n",
      "  Fairness: 0.578\n",
      "  System 1 Usage: 1.000\n",
      "\n",
      "Running scenario: Polarized Cognition\n",
      "  Cooperation: 0.560\n",
      "  Welfare: 137.00\n",
      "  Equality: 0.623\n",
      "  Fairness: 0.000\n",
      "  System 1 Usage: 1.000\n",
      "\n",
      "==================================================\n",
      "Experiment Complete\n",
      "==================================================\n",
      "\n",
      "Summary Results:\n",
      "           scenario system1_distribution           game_type  cooperation_rate  total_welfare  equality  fairness  system1_usage\n",
      " High System 1 Bias               skewed   prisoners_dilemma           0.47164          133.0  0.612481  0.000000            1.0\n",
      " Balanced Cognition              uniform   prisoners_dilemma           0.53124          142.0  0.653803  0.000000            1.0\n",
      "Resource Allocation              uniform resource_allocation           0.00000         1000.0  0.916497  0.578047            1.0\n",
      "Polarized Cognition              bimodal   prisoners_dilemma           0.55992          137.0  0.623212  0.000000            1.0\n",
      "\n",
      "Results saved to CSV files:\n",
      " - dual_process_results.csv (summary)\n",
      " - model_timeseries.csv (model-level time series)\n",
      " - agent_data.csv (agent-level data)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the experiment\n",
    "    results_df, model_data, agent_data = run_experiment()\n",
    "    \n",
    "    # Display summary of results\n",
    "    print(\"\\nSummary Results:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Save results to files\n",
    "    # results_df.to_csv(\"dual_process_results.csv\", index=False)\n",
    "    # model_data.to_csv(\"model_timeseries.csv\")\n",
    "    # agent_data.to_csv(\"agent_data.csv\")\n",
    "    \n",
    "    print(\"\\nResults saved to CSV files:\")\n",
    "    print(\" - dual_process_results.csv (summary)\")\n",
    "    print(\" - model_timeseries.csv (model-level time series)\")\n",
    "    print(\" - agent_data.csv (agent-level data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ce8b9-094c-466c-9ae2-85e62ddc98af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
